# 优云智算GPU平台部署GPT-SoVITS完整指南

## 📋 目录
1. [平台实例配置选择](#1-平台实例配置选择)
2. [Ubuntu系统初始化](#2-ubuntu系统初始化)
3. [文件传输方案](#3-文件传输方案)
4. [环境部署步骤](#4-环境部署步骤)
5. [运行和测试](#5-运行和测试)
6. [常见问题解决](#6-常见问题解决)
7. [性能优化建议](#7-性能优化建议)

---

## 1. 平台实例配置选择

### 🎯 推荐配置方案

#### 方案一：入门级配置（适合测试和轻量使用）
- **GPU**: RTX 3060 (12GB) 或 RTX 4060 Ti (16GB)
- **CPU**: 8核心以上
- **内存**: 32GB
- **存储**: 100GB SSD
- **网络**: 按需选择
- **预估费用**: 2-4元/小时

#### 方案二：标准配置（推荐）
- **GPU**: RTX 4070 (12GB) 或 RTX 4080 (16GB)
- **CPU**: 12核心以上
- **内存**: 64GB
- **存储**: 200GB SSD
- **网络**: 按需选择
- **预估费用**: 4-8元/小时

#### 方案三：高性能配置（适合批量处理）
- **GPU**: RTX 4090 (24GB) 或 A100 (40GB/80GB)
- **CPU**: 16核心以上
- **内存**: 128GB
- **存储**: 500GB SSD
- **网络**: 按需选择
- **预估费用**: 8-20元/小时

### 🔧 配置选择要点

1. **GPU显存要求**：
   - 最低12GB（基础模型）
   - 推荐16GB+（完整功能）
   - 24GB+（大模型和批量处理）

2. **内存要求**：
   - 最低32GB
   - 推荐64GB+（避免内存不足）

3. **存储要求**：
   - 系统和依赖：~30GB
   - 模型文件：~20-50GB
   - 工作空间：~50GB
   - 总计推荐：100GB+

4. **操作系统选择**：
   - **Ubuntu 20.04 LTS** 或 **Ubuntu 22.04 LTS**
   - 确保选择带CUDA的镜像（如果有）

---

## 2. Ubuntu系统初始化

### 🚀 开机后首次配置

#### 步骤1：连接到实例
```bash
# 使用SSH连接（优云智算会提供连接信息）
ssh root@your-instance-ip
# 或使用提供的Web终端
```

#### 步骤2：系统更新
```bash
# 更新软件包列表
apt update

# 升级系统包
apt upgrade -y

# 安装基础工具
apt install -y wget curl git vim htop tree unzip
```

#### 步骤3：检查GPU状态
```bash
# 检查NVIDIA驱动
nvidia-smi

# 检查CUDA版本
nvcc --version

# 如果没有CUDA，安装CUDA Toolkit
wget https://developer.download.nvidia.com/compute/cuda/12.6.0/local_installers/cuda_12.6.0_560.28.03_linux.run
chmod +x cuda_12.6.0_560.28.03_linux.run
./cuda_12.6.0_560.28.03_linux.run
```

#### 步骤4：安装Anaconda
```bash
# 下载Anaconda
cd /tmp
wget https://repo.anaconda.com/archive/Anaconda3-2024.10-1-Linux-x86_64.sh

# 安装Anaconda
chmod +x Anaconda3-2024.10-1-Linux-x86_64.sh
./Anaconda3-2024.10-1-Linux-x86_64.sh

# 重新加载shell配置
source ~/.bashrc

# 验证安装
conda --version
```

#### 步骤5：安装系统依赖
```bash
# 安装音频处理依赖
apt install -y ffmpeg libsox-dev

# 安装其他必要依赖
apt install -y build-essential libssl-dev libffi-dev python3-dev

# 安装中文字体支持（可选）
apt install -y fonts-noto-cjk
```

---

## 3. 文件传输方案

### 📁 方案一：直接下载（推荐）
```bash
# 创建工作目录
mkdir -p /workspace/gpt-sovits
cd /workspace/gpt-sovits

# 如果你的整合包在GitHub或其他代码仓库
git clone your-repository-url .

# 或者从网盘下载（需要提供下载链接）
wget "your-download-link" -O gpt-sovits-package.zip
unzip gpt-sovits-package.zip
```

### 📁 方案二：SCP传输
```bash
# 在本地电脑上执行（将整合包压缩后传输）
# 首先在本地压缩整合包
tar -czf gpt-sovits-package.tar.gz GPT-SoVITS-v2pro-20250604/

# 传输到云服务器
scp gpt-sovits-package.tar.gz root@your-instance-ip:/workspace/

# 在云服务器上解压
cd /workspace
tar -xzf gpt-sovits-package.tar.gz
```

### 📁 方案三：网盘同步
```bash
# 使用rclone同步网盘文件（以百度网盘为例）
# 安装rclone
curl https://rclone.org/install.sh | sudo bash

# 配置网盘（按提示操作）
rclone config

# 同步文件
rclone copy your-cloud-drive:/path/to/package /workspace/gpt-sovits/
```

---

## 4. 环境部署步骤

### 🔨 完整部署流程

#### 步骤1：进入项目目录
```bash
cd /workspace/gpt-sovits/GPT-SoVITS-v2pro-20250604
```

#### 步骤2：检查文件完整性
```bash
# 运行系统检查脚本
./check-ubuntu-setup.sh
```

#### 步骤3：运行安装脚本
```bash
# 给脚本执行权限
chmod +x *.sh

# 运行Ubuntu安装脚本（推荐配置）
./install-ubuntu.sh --device CU128 --source HF-Mirror --download-uvr5

# 或者根据你的GPU选择合适的CUDA版本
# CUDA 12.6: --device CU126
# 仅CPU: --device CPU
```

#### 步骤4：等待安装完成
```bash
# 安装过程可能需要20-60分钟，取决于网络速度
# 可以使用screen或tmux在后台运行
screen -S install
./install-ubuntu.sh --device CU128 --source HF-Mirror --download-uvr5
# 按Ctrl+A+D分离会话，稍后用screen -r install重新连接
```

#### 步骤5：验证安装
```bash
# 激活conda环境
conda activate GPTSoVits

# 检查Python和依赖
python --version
pip list | grep torch
```

---

## 5. 运行和测试

### 🎮 启动服务

#### 启动WebUI（推荐新手）
```bash
# 启动Web界面
./go-webui.sh

# 服务启动后会显示访问地址，通常是：
# http://0.0.0.0:9874 或 http://localhost:9874
```

#### 启动API服务器
```bash
# 启动API服务器
./api-server.sh

# 或使用简洁版本
./接口.sh
```

### 🌐 外网访问配置

#### 方法1：端口映射（推荐）
```bash
# 在启动时指定监听所有IP
python webui.py --server_name 0.0.0.0 --server_port 9874

# 确保云平台开放了对应端口（9874）
```

#### 方法2：使用内网穿透
```bash
# 安装frp客户端
wget https://github.com/fatedier/frp/releases/download/v0.52.3/frp_0.52.3_linux_amd64.tar.gz
tar -xzf frp_0.52.3_linux_amd64.tar.gz

# 配置frp客户端（需要有frp服务器）
# 或使用其他内网穿透工具如ngrok
```

### 🧪 功能测试

#### 基础功能测试
```bash
# 测试API接口
curl -X GET http://localhost:9880/

# 测试模型加载
# 通过WebUI界面上传音频文件进行测试
```

---

## 6. 常见问题解决

### ❗ GPU相关问题

#### 问题1：CUDA版本不匹配
```bash
# 检查CUDA版本
nvcc --version
nvidia-smi

# 重新安装对应版本的PyTorch
pip uninstall torch torchvision torchaudio
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

#### 问题2：GPU内存不足
```bash
# 检查GPU使用情况
nvidia-smi

# 清理GPU缓存
python -c "import torch; torch.cuda.empty_cache()"

# 降低batch size或模型精度
```

### ❗ 网络相关问题

#### 问题1：模型下载失败
```bash
# 使用国内镜像源
export HF_ENDPOINT=https://hf-mirror.com

# 或手动下载模型文件
wget https://hf-mirror.com/model-path/model-file
```

#### 问题2：依赖安装失败
```bash
# 使用国内pip源
pip install -i https://pypi.tuna.tsinghua.edu.cn/simple package-name

# 或配置永久镜像源
pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple
```

### ❗ 系统资源问题

#### 问题1：内存不足
```bash
# 检查内存使用
free -h
htop

# 增加swap空间
fallocate -l 8G /swapfile
chmod 600 /swapfile
mkswap /swapfile
swapon /swapfile
```

#### 问题2：磁盘空间不足
```bash
# 检查磁盘使用
df -h

# 清理不必要文件
conda clean --all
pip cache purge
apt autoremove
```

---

## 7. 性能优化建议

### ⚡ 系统优化

#### GPU性能优化
```bash
# 设置GPU性能模式
nvidia-smi -pm 1

# 设置最大功耗
nvidia-smi -pl 300  # 根据GPU型号调整
```

#### 内存优化
```bash
# 优化Python内存管理
export PYTHONMALLOC=malloc
export MALLOC_ARENA_MAX=1

# 设置PyTorch内存分配策略
export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:128
```

#### 网络优化
```bash
# 设置模型缓存目录
export HF_HOME=/workspace/cache/huggingface
export TRANSFORMERS_CACHE=/workspace/cache/transformers

# 预下载常用模型
python -c "from transformers import AutoModel; AutoModel.from_pretrained('model-name')"
```

### 📊 监控和日志

#### 系统监控
```bash
# 安装监控工具
apt install -y htop iotop nethogs

# 实时监控GPU
watch -n 1 nvidia-smi

# 监控磁盘IO
iotop

# 监控网络
nethogs
```

#### 日志管理
```bash
# 查看应用日志
tail -f logs/app.log

# 设置日志轮转
logrotate /etc/logrotate.conf
```

---

## 🎯 快速启动脚本

创建一个一键启动脚本：

```bash
#!/bin/bash
# 文件名：quick-start.sh

echo "=== GPT-SoVITS 快速启动 ==="

# 检查环境
if ! command -v conda &> /dev/null; then
    echo "❌ Conda未安装"
    exit 1
fi

# 激活环境
source ~/.bashrc
conda activate GPTSoVits

# 检查GPU
if ! nvidia-smi &> /dev/null; then
    echo "⚠️  GPU不可用，将使用CPU模式"
fi

# 启动服务
echo "🚀 启动WebUI服务..."
./go-webui.sh

echo "✅ 服务已启动"
```

---

## 📞 技术支持

如果遇到问题，可以：

1. 查看 <mcfile name="README-Ubuntu.md" path="d:\doucument\do_current\GPT\GPT-SoVITS-v2pro-20250604\README-Ubuntu.md"></mcfile>
2. 运行 `./check-ubuntu-setup.sh` 进行系统检查
3. 查看 <mcfile name="MIGRATION-NOTES.md" path="d:\doucument\do_current\GPT\GPT-SoVITS-v2pro-20250604\MIGRATION-NOTES.md"></mcfile> 了解技术细节

---

**祝你部署顺利！🎉**